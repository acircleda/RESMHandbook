# Statistics in R
  
## T-Tests
INTRO STATEMENT ON T-TESTS HERE

### Independent Means T-Test
Define Independent Means T-Test (*Cite Gravetter and Wallnau*)

For the Independent Means T-Test in this section, we will be using a fake data set of a sample of 200 undergraduate students' math test scores. The test scores are on a scale of 0 to 100, and each individual has been assigned to either the Paper Test format or the Electronic Test format in the TestFormat condition, where 1=paper test and -1=electronic test.The following lines of code create our data set and set up the data frames we will need.
```{r echo = T}
set.seed(100)
PaperGrade<-rnorm(n = 100, mean = 70, sd = 10)
set.seed(1000)
ElectronicGrade<-rnorm(n = 100, mean = 65, sd = 13)

Grade<-c(PaperGrade,ElectronicGrade)
TestFormat<-c(rep(1,100),rep(-1,100))

Data<-data.frame(Grade, TestFormat)

N<-200
```

Before continuing with this section, the following packages must be installed a loaded in order to successfully run all of the functions listed.
```{r, echo=T, message=FALSE, warning=FALSE}
library(pwr)
library(car)
library(effsize)
```

#### Assumptions
There are five assumptions that we should meet in order to conduct this t-test:

* Having an itnterval or ratio scale of measurement
* Using a random sampling from a defined population
* The samples are independent; no overlap between group members
* The scores are normally distributed in the population
* There is homogeneity of variance

The first three assumptions can be checked simply by looking at our data. We have a ratio scale of measurement, it is a random sample, and the samples are independent. The normality assumption can be checked using the Shapiro-Wilk test. 
```{r echo=T}
shapiro.test(Grade)
```

As we can see here, the p-value for the Shapiro-Wilk test was 0.6175, which indicates that there was no violation of normality.

The homogeneity of variance assumption can be tests using either Levene's test for homogeneity of variance or Bartlett's test. Notice that in the code for the Levene's test we used as.factor. This is because our data is set up as contrast codes, but Levene's test needs groups!
```{r echo = T}
leveneTest(Grade~as.factor(TestFormat))
bartlett.test(Data$Grade, Data$TestFormat)
```
As we can see here, the p-value for the Levene's test was 0.029 and the Bartlett's test was 0.014, both of which indicate a violation of the assumption. However, for the sake of the example, we will continue with conducting the analysis.

#### Test Statistic
In order to compute the Independent Mean T-Test, we can use the `summary()` and `lm()` functions or the `t.test()` function. For both of these, type the dependent variable first and then the independent variable.
```{r echo = T}
summary(lm(Grade~TestFormat))
t.test(Grade~TestFormat)
```

In this output we can see that the t value is -2.902, and our p value is less than .01, meaning we have a significant result.

We can also use the `confint()` and `lm()` functions to calculate a confidence interval for the test.
```{r}
confint(lm(Grade~TestFormat))
```

This gives us a 95% confidence interval of 65.984 to 69.257.

Once we have calulated the t value and p-value, we can then calculate the effect size, or Choen's d, using the following code:
```{r echo = T}
cohen.d(Grade~as.factor(TestFormat))
cohensD<-cohen.d(Grade~as.factor(TestFormat))[["estimate"]]
```
Our Cohen's d was 0.41, which is a small effect size based on Cohen's conventions (*Need citation*)

We can also calculate the power for the obtained effect size using the `pwr.t.test()` function from the `pwr` package. 
```{r echo = T}
pwr.t.test(n = N/2, d = cohensD, sig.level = .05, type = "two.sample")
```

This shows us our power is 94%.

In the pwr.t.test function you must enter values for at least three of the following four arguments:

  * `n =` number in each group
  * `d =` Cohen's d
  * `sig.level =` alpha from T-Test
  * `power =` desired power

As well as the `type=` argument, which indicates whether you are using a `"two.sample"`, `"one.sample"`, or `"paired"` t-test. Whichever argument you leave blank will be the value that the function calculates based on the other values. In our example, we wanted to determine the observed power so we left it blank and provided the number in each group, Cohen's d, and alpha.

Once you have finished these steps, you can move on to writing up and reporting your results.

### Depenednt Means T-Test
Define Dependent Means T-Test (*Cite Gravetter and Wallnau*)

## Chi Square
Chi Square tests are non-parametric, or distribution free, tests that compare the proportions observed in our sample verses the proportions expected. There are two different Chi Square tests: the Goodness of Fit test and the Test of Independence.

### Chi Square Goodness of Fit
The Chi Square Goodness of Fit test is used to test the proportions obtained from a sample against the null hypothesis about the corresponding proportions in the population (*Cite Gravetter and Wallnau*).

For this section, we will be creating a fake data set to work with. In this scenario, We asked 100 students if their favorite subject is math, science,  or reading. Each student was only allowed to pick one favorite and it had to be one of these three. This resulted in 55 students choosing math, 15 chosing science, and remaining 30 selecting reading. The following code creates this data.

```{r echo = T}
counts <-c(55, 15, 30)
subjects <- c("math","science","reading")
```

Before continuing with this section, the `pwr` package must be installed and loaded in order to successfully run all of the functions listed.

```{r echo=T, message=FALSE, warning=FALSE}
library(pwr)
```

#### Assumptions
There are four assumptions that must be checked prior to conducting a goodness of fit test:

* There is one categorical variable
* Indepenence of observations
* Mutually exculisive groups
* At least 5 expected frequencies in each group

The first three assumptions can be checked simply by looking at our data. There is a categorical variable (subject), no observation influences another, and no observation exsits in more than one group. The final assumption can be checked by calculating the expected values for the groups using the following code.

```{r echo = T}
N <-sum(counts)
N
k <- length(counts)
k
df<-k-1
df
Expected <- N/k
Expected
```
Here we can see that the expected value for each group is 33.33.

**Note about expected values**

Expected values often have decimals which are not possible when observing count data. This is to be expected, and will not impact the results of the Chi Square test. 

#### Test Statistic
In order to compute the Chi Square Goodness of Fit test, we can use the `chisq.test()` function from the `pwr` package.

```{r echo = T}
mychi<-chisq.test(counts)
mychi
```

In this output we can see that the Chi Square statistic is 24.5, and our p value is less than .001, meaning we have a significant result.

Once we have calulated the Chi Square and p value, we can then calculate the effect size, or Phi coefficient, and the power for the test. These can be done using the following code:

```{r echo = T}
phi<-sqrt((as.numeric(mychi[1])/N))
phi
pwr.chisq.test(phi, N, df, sig.level=.05, power=NULL)
```

This shows us our Phi is .495 and the power is 94%. Once you have finished these steps, you can move on to writing up and reporting your results.

### Chi Square Test of Independence

## Regression

## Analysis of Variance (ANOVA)
INTRO STATEMENT ON ANOVAs HERE

### One-Way Between Subjects ANOVA

Define One-Way BS ANOVA (*Cite Gravetter and Wallnau*)

For the One-way Between Subjects ANOVA in this section, we will be using a fake data set of a sample of 300 undergraduate students' math test scores. The test scores are on a scale of 0 to 100. Each individual has also been assigned to either test 1, 2, or 3 the TestNumber condition. The following lines of code create our data set and set up the data frame we will need.
```{r}
set.seed(100)
Test1<-rnorm(n = 100, mean = 70, sd = 10)
set.seed(1000)
Test2<-rnorm(n = 100, mean = 65, sd = 13)
set.seed(10000)
Test3<-rnorm(n = 100, mean = 90, sd = 2)

Grades<-c(Test1,Test2,Test3)
TestNumber<-c(rep(1,100),rep(2,100),rep(3,100))

Data<-data.frame(Grades, TestNumber)
```

Before continuing with this section, the following package must be installed a loaded in order to successfully run all of the functions listed.
```{r, echo=T, message=FALSE, warning=FALSE}
library(agricolae)
```

#### Assumptions
There are four assumptions that we should meet in order to conduct this ANOVA:

* Having an itnterval or ratio scale of measurement
* The samples are independent; no overlap between group members
* The scores are normally distributed in the population
* There is homogeneity of variance

The first two assumptions can be checked simply by looking at our data. We have a ratio scale of measurement and the samples are independent. The normality assumption can be checked using the Shapiro-Wilk test on each group. 
```{r echo=T}
shapiro.test(Data$Grades[which(Data$TestNumber==1)])
shapiro.test(Data$Grades[which(Data$TestNumber==2)])
shapiro.test(Data$Grades[which(Data$TestNumber==3)])
```

As we can see here, the p-value for the Shapiro-Wilk tests were 0.535, 0.79, and 0.178, which indicates no violation of the assumption.

The homogeneity of variance assumption can be tests using either Levene's test for homogeneity of variance or Bartlett's test. Notice that in the code for the Levene's test we used as.factor. This is because our data is set up as contrast codes, but Levene's test needs groups!
```{r echo = T}
leveneTest(Data$Grades,as.factor(Data$TestNumber))
bartlett.test(Data$Grades,Data$TestNumber)
```
As we can see here, the p-value for both the Levene's test and Bartlett's test were less than .001, which indicates a violation of the assumption. However, for the sake of the example, we will continue with conducting the analysis.

#### Test Statistic
In order to compute the ANOVA, we will use the `anova()` and `lm()` functions together. Within the `lm()` function, type the dependent variable first and then the independent variable.
```{r echo = T}
myanova<-anova(lm(Data$Grades~Data$TestNumber))
myanova
```

In this output we can see that the F value is 143.37, and our p value is less than .001, meaning we have a significant result.


Once we have calulated the F value and p-value, we can then calculate the effect size, or R squared, using the following code:
```{r echo = T}
SSbetween <- myanova[1,2]
SSerror <- myanova[2,2]
(R2 <- SSbetween / (SSbetween+SSerror))
```

Our R squared was 0.325, which means that 32.5% of the variation in grades is explained by test number.

#### Post Hoc Test
Finally, because our ANOVA was significant, we need to conduct post hoc tests to determine which groups were significantly different from each other. This can be done using Fisher's least significant difference (LSD) test. The `LSD.test` function is located in the `agricolae` package.
```{r}
DFerror <- myanova[2,1]
MSE <- myanova[1,3]

LSD.test(Data$Grades,Data$TestNumber, DFerror, MSE,console=TRUE)
```

This test indicates that there are no significant differences between any of the groups.

Once you have finished these steps, you can move on to writing up and reporting your results.

### One-Way Within Subjects ANOVA

## Multivariate Analysis of Variance (MANOVA)

## Analysis of Covariance (ANCOVA)

## Logistic Regression

## Factor Analysis

## Power Analysis